import numpy as np
import torch
from torch.utils.data import Dataset

from colour_bomb import ColourBombGridworldV1Env, CBConfig


class CBSequenceDataset(Dataset):
    """
    Sequence dataset for Colour Bomb Gridworld v1.

    Each episode is generated by taking random actions in the gridworld.
    For each timestep t we store a 4-dimensional "transition token":
        [state_t, action_t, 0, 0]
    so that:
        observation_dim = 1
        action_dim      = 1
        joined_dim      = 4

    These flattened transitions are sliced into fixed-length sequences:
        x: seq_len tokens
        y: next-token targets
        mask: 1 for all positions (no padding here).
    """

    def __init__(
        self, num_episodes=1000, max_steps=200, sequence_length=200,
        discount=0.99, stochastic=False, seed=0
    ):
        self.sequence_length = sequence_length
        self.discount = discount

        cfg = CBConfig(max_steps=max_steps, stochastic=stochastic)
        self.env = ColourBombGridworldV1Env(cfg)

        rng = np.random.RandomState(seed)

        episodes_tokens = []

        for _ in range(num_episodes):
            s, _ = self.env.reset()
            states = []
            actions = []
            rewards = []
            
            for t in range(max_steps):
                a = rng.randint(self.env.action_space.n)
                ns, r, done, _ = self.env.step(a)
                states.append(s)
                actions.append(a)
                rewards.append(r)
                s = ns
                if done:
                    break

            T = len(states)
            if T == 0:
                continue

            values = np.zeros(T, dtype=np.float32)
            g = 0.0
            for t in reversed(range(T)):
                g = rewards[t] + discount * g
                values[t] = g

            tokens = np.zeros((T, 4), dtype=np.int64)
            for t in range(T):
                tokens[t, 0] = int(states[t])
                tokens[t, 1] = int(actions[t])
                tokens[t, 2] = 0
                tokens[t, 3] = 0

            # append an end/stop transition so DFAs can observe episode termination
            max_bin = max(self.env.observation_space.n, self.env.action_space.n, 1)
            end_token = max_bin  # aligns with adapter.num_token_ids - 1
            end_row = np.array([end_token] * 4, dtype=np.int64)
            tokens = np.vstack([tokens, end_row])

            flat = tokens.reshape(-1)
            episodes_tokens.append(flat)

        indices = []
        for ep_idx, flat in enumerate(episodes_tokens):
            L = flat.shape[0]
            if L < sequence_length + 1:
                continue
            starts = list(range(0, max(1, L - sequence_length), sequence_length))
            last_start = L - (sequence_length + 1)
            if last_start not in starts:
                starts.append(last_start)
            for start in starts:
                indices.append((ep_idx, start))

        self.episodes_tokens = episodes_tokens
        self.indices = indices

        self.observation_dim = 1
        self.action_dim = 1
        self.joined_dim = 4

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        ep_idx, start = self.indices[idx]
        flat = self.episodes_tokens[ep_idx]
        seg = flat[start:start + self.sequence_length + 1]
        x = torch.from_numpy(seg[:-1].astype(np.int64))
        y = torch.from_numpy(seg[1:].astype(np.int64))
        mask = torch.ones_like(x, dtype=torch.float32)
        return x, y, mask
